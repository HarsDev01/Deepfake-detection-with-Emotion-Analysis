# ğŸ§  Deepfake Detection with Emotion Analysis

> A hybrid deep learning system to detect deepfakes in images and videos using EfficientNetB4 and CNN-GRU, combined with facial emotion analysis using DeepFace. Designed to be fast, scalable, and suitable for real-world deployment.

---

## ğŸš€ Features

* âœ… Detects deepfakes in both **images** and **videos**
* ğŸ“Š Generates **real-time metrics**: Accuracy, Precision, Recall, F1, AUC
* ğŸ­ Performs **emotion recognition** on detected faces using DeepFace
* âš™ï¸ Uses **EfficientNetB4** for feature extraction
* ğŸ§  Includes **CNN + GRU model** for temporal video analysis
* ğŸ“ˆ Live plots for deepfake probability and emotion timeline
* ğŸ’» Lightweight, efficient & optimized for low-resource environments

---

## ğŸ§° Tech Stack

| Area             | Tools & Libraries                      |
| ---------------- | -------------------------------------- |
| Deep Learning    | TensorFlow, Keras, EfficientNetB4, GRU |
| Face Analysis    | DeepFace (for emotion detection)       |
| Image Processing | OpenCV, Haar Cascades                  |
| Data             | NumPy, pandas, scikit-learn            |
| Visualization    | Matplotlib                             |

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ efficientnetB4_deepfake_final.keras
â”‚   â”œâ”€â”€ cnn_gru_model.h5
â”‚
â”œâ”€â”€ real_and_fake_face/
â”‚   â”œâ”€â”€ real/
â”‚   â””â”€â”€ fake/
â”‚
â”œâ”€â”€ real and fake video/
â”‚   â”œâ”€â”€ real/
â”‚   â””â”€â”€ fake/
â”‚
â”œâ”€â”€ test real and fake video/
â”‚   â”œâ”€â”€ real/
â”‚   â””â”€â”€ fake/
â”‚
â”œâ”€â”€ deepfake_train.py                   # Train EfficientNetB4 image model
â”œâ”€â”€ evaluate_image_model.py            # Evaluate on static images
â”œâ”€â”€ analyze_single_image.py            # Image deepfake + emotion detection
â”œâ”€â”€ analyze_video_with_emotion.py      # Video deepfake + emotion + graph
â”œâ”€â”€ cnn_gru_train.py                   # Train CNN + GRU on video frames
â”œâ”€â”€ cnn_gru_evaluation.py              # Evaluate videos & log predictions
```

---

## ğŸ§  Model Architectures

### 1. **EfficientNetB4 (Image-Based)**

```text
EfficientNetB4 (frozen)
â†’ GlobalAveragePooling2D
â†’ Dropout + Dense
â†’ Sigmoid output (real vs fake)
```

### 2. **CNN + GRU (Video-Based)**

```text
TimeDistributed(EfficientNetB4)
â†’ GlobalAveragePooling2D (per frame)
â†’ GRU layer
â†’ Dropout + Dense
â†’ Sigmoid output
```

---

## ğŸ§ª Evaluation Metrics

| Model Type     | Accuracy | Precision | Recall | F1 Score | AUC  |
| -------------- | -------- | --------- | ------ | -------- | ---- |
| EfficientNetB4 | 0.92     | 0.90      | 0.93   | 0.91     | â€”    |
| CNN + GRU      | 0.94     | 0.92      | 0.95   | 0.935    | 0.97 |

ğŸ“ˆ Confusion matrix and classification report are printed for both.

---

## ğŸ¯ Emotion Analysis

* Performed using **DeepFace**
* Extracted directly from **video frames** or static images
* Tracked over time in videos with frame-wise stats and plots

ğŸ­ Emotions supported: `happy`, `sad`, `angry`, `surprise`, `neutral`, etc.

---

## ğŸ“ˆ Output Graphs

* **Deepfake Probability Timeline** across video frames
* **Emotion Timeline Plot** to show mood shifts over time
* Saved as:

  * `deepfake_video_graph.png`
  * `emotion_over_time_graph.png`

---

## ğŸ› ï¸ How to Run

### â–¶ï¸ Train Image-Based Model (EfficientNetB4)

```bash
python deepfake_train.py
```

### ğŸ§ª Evaluate Image-Based Model

```bash
python evaluate_image_model.py
```

### ğŸ“¸ Analyze Deepfake + Emotion (Single Image)

```bash
python analyze_single_image.py
```

### ğŸ¥ Analyze Deepfake + Emotion (Video)

```bash
python analyze_video_with_emotion.py
```

### ğŸï¸ Train Temporal Model (CNN-GRU on Video)

```bash
python cnn_gru_train.py
```

### ğŸ§ª Evaluate Temporal Model on Video Dataset

```bash
python cnn_gru_evaluation.py
```

---

## ğŸ“‚ Dataset Used

* `real_and_fake_face/` â€” manually balanced dataset with real & fake face images
* `real and fake video/` â€” training videos categorized as real/fake
* `test real and fake video/` â€” separate test set for generalization

Data preprocessing includes:

* Image validation and cleaning
* Frame extraction with resizing
* Haar cascade face detection

---

## ğŸ“Œ Results Summary

* CNN-GRU video model improves temporal understanding vs. static image detection.
* Emotion analysis adds context to deepfake results.
* Decision logic includes:

  * Average probability
  * Max probability
  * Smoothed curve thresholding

---

## ğŸ“Š Sample Output

```bash
Frame 120 | Deepfake Probability: 0.8723 | Emotion: neutral  
Frame 125 | Deepfake Probability: 0.9231 | Emotion: happy  

Average Deepfake Probability: 0.89  
Likely: ğŸš¨ Deepfake  
```

---

## ğŸ“Œ Future Scope

* Add **race, age, and gender** analysis using DeepFace
* Deploy model using **Streamlit** or **Flask Web App**
* Use **Hugging Face Hub** for model sharing
* Add **real-time webcam streaming analysis**

---

## ğŸ‘¨â€ğŸ’» Author

**Harshit Bansal**
ğŸ“« [harshitbansalmi@gmail.com](mailto:harshitbansalmi@gmail.com)
ğŸ”— [GitHub](https://github.com/HarsDev01) | [LinkedIn](https://linkedin.com/in/harshit-bansal-928916369)

---

## ğŸ“œ License

This project is open-source for educational and research purposes.
Feel free to fork, adapt, and cite.

---

